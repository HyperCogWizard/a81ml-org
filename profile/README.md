### Projects

```mermaid
graph TD;
ggml --> whisper.cpp
ggml --> llama.cpp
llama.cpp --> llama.vim
llama.cpp --> llama.vscode

ggml[<a href="https://github.com/ggml-org/ggml" style="text-decoration:none;">ggml</a>];
whisper.cpp[<a href="https://github.com/ggerganov/whisper.cpp" style="text-decoration:none;">whisper.cpp</a>];
llama.cpp[<a href="https://github.com/ggerganov/llama.cpp" style="text-decoration:none;">llama.cpp</a>];
llama.vim[<a href="https://github.com/ggml-org/llama.vim" style="text-decoration:none;">llama.vim</a>];
llama.vscode[<a href="https://github.com/ggml-org/llama.vscode" style="text-decoration:none;">llama.vscode</a>];
```

### Info

- Cloud: https://endpoints.huggingface.co ([tutorial](https://huggingface.co/docs/inference-endpoints/en/guides/llamacpp_container))
- Jobs: jobs@ggml.ai *(full-time, only active contributors will be considered)*
  - `ggml`/`llama.cpp` maintainer
- Business: sales@ggml.ai
