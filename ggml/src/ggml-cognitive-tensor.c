#include "ggml-cognitive-tensor.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <assert.h>

// Prime number generation using Sieve of Eratosthenes
static void generate_primes(uint32_t* primes, size_t* count, uint32_t limit) {
    bool* is_prime = calloc(limit + 1, sizeof(bool));
    for (uint32_t i = 2; i <= limit; i++) {
        is_prime[i] = true;
    }
    
    *count = 0;
    for (uint32_t i = 2; i <= limit; i++) {
        if (is_prime[i]) {
            primes[(*count)++] = i;
            if (*count >= GGML_COGNITIVE_MAX_PRIMES) break;
            
            for (uint32_t j = i * i; j <= limit; j += i) {
                is_prime[j] = false;
            }
        }
    }
    
    free(is_prime);
}

// Initialize prime lookup table
void ggml_init_prime_lookup(ggml_prime_lookup_t* lookup) {
    if (lookup->initialized) return;
    
    // Generate primes up to a reasonable limit
    generate_primes(lookup->primes, &lookup->prime_count, 10000);
    lookup->initialized = true;
    
    printf("Initialized prime lookup with %zu primes\n", lookup->prime_count);
}

// Get nth prime number
uint32_t ggml_nth_prime(uint32_t n) {
    static ggml_prime_lookup_t static_lookup = {0};
    
    if (!static_lookup.initialized) {
        ggml_init_prime_lookup(&static_lookup);
    }
    
    if (n == 0 || n > static_lookup.prime_count) {
        return 0; // Invalid index
    }
    
    return static_lookup.primes[n - 1];
}

// Prime offset function: p(n) = (n+1)-th prime
uint32_t ggml_prime_offset(uint32_t n) {
    return ggml_nth_prime(n + 1);
}

// Check if number is prime
bool ggml_is_prime(uint32_t n) {
    if (n < 2) return false;
    if (n == 2) return true;
    if (n % 2 == 0) return false;
    
    for (uint32_t i = 3; i * i <= n; i += 2) {
        if (n % i == 0) return false;
    }
    return true;
}

// Simple tree expression parser for Matula-Goebel encoding
static uint32_t parse_tree_expression(const char* expr, size_t* pos) {
    size_t len = strlen(expr);
    
    if (*pos >= len) return 1; // Empty tree maps to 1
    
    if (expr[*pos] == '(') {
        (*pos)++; // Skip '('
        
        uint32_t result = 1;
        
        // Parse subtrees
        while (*pos < len && expr[*pos] != ')') {
            uint32_t subtree = parse_tree_expression(expr, pos);
            if (subtree > 0) {
                uint32_t prime = ggml_prime_offset(subtree);
                result *= prime;
            }
        }
        
        if (*pos < len && expr[*pos] == ')') {
            (*pos)++; // Skip ')'
        }
        
        return result;
    } else {
        // Leaf node or atomic expression
        return 1;
    }
}

// Encode tree expression using Matula-Goebel prime offset
ggml_matula_encoding_t ggml_encode_tree(const char* tree_expression, ggml_prime_lookup_t* prime_cache) {
    ggml_matula_encoding_t encoding = {0};
    
    if (!tree_expression || strlen(tree_expression) == 0) {
        encoding.matula_value = 1;
        encoding.system_level = 1;
        encoding.phase = 1.0f + 0.0f * I;
        return encoding;
    }
    
    size_t pos = 0;
    encoding.matula_value = parse_tree_expression(tree_expression, &pos);
    
    // Determine system level based on Matula value
    encoding.system_level = ggml_matula_decode_system_level(encoding.matula_value);
    
    // Encode quantum phase
    encoding.phase = ggml_quantum_phase_encode(encoding.matula_value, 0.0f);
    
    // Simple breadth/depth assignment (could be more sophisticated)
    encoding.breadth_index = encoding.matula_value % GGML_COGNITIVE_MAX_BREADTH;
    encoding.depth_index = (encoding.matula_value / GGML_COGNITIVE_MAX_BREADTH) % GGML_COGNITIVE_MAX_DEPTH;
    
    return encoding;
}

// Decode system level from Matula value
uint32_t ggml_matula_decode_system_level(uint32_t matula_value) {
    if (matula_value == 1) return 1;
    if (matula_value <= 4) return 2;
    if (matula_value <= 9) return 3;
    if (matula_value <= 16) return 4;
    
    // For larger values, use log-based approximation
    return (uint32_t)(log2(matula_value)) + 1;
}

// Factorize Matula value into prime factors
void ggml_matula_factorize(uint32_t matula_value, uint32_t* factors, size_t* factor_count) {
    *factor_count = 0;
    uint32_t n = matula_value;
    
    // Handle factor 2
    while (n % 2 == 0) {
        factors[(*factor_count)++] = 2;
        n /= 2;
    }
    
    // Handle odd factors
    for (uint32_t i = 3; i * i <= n; i += 2) {
        while (n % i == 0) {
            factors[(*factor_count)++] = i;
            n /= i;
        }
    }
    
    if (n > 2) {
        factors[(*factor_count)++] = n;
    }
}

// Quantum phase encoding
ggml_complex_t ggml_quantum_phase_encode(uint32_t matula_value, float phase_parameter) {
    float phase = fmodf(phase_parameter + (float)matula_value * 0.1f, 2.0f * M_PI);
    return cosf(phase) + sinf(phase) * I;
}

// Initialize cognitive kernel tensor
ggml_cognitive_kernel_t* ggml_cognitive_kernel_init(
    struct ggml_context* ctx,
    uint32_t max_systems,
    uint32_t max_breadth,
    uint32_t max_depth) {
    
    ggml_cognitive_kernel_t* kernel = calloc(1, sizeof(ggml_cognitive_kernel_t));
    if (!kernel) return NULL;
    
    kernel->max_systems = max_systems;
    kernel->max_breadth = max_breadth;
    kernel->max_depth = max_depth;
    
    // Initialize prime lookup
    ggml_init_prime_lookup(&kernel->prime_cache);
    
    // Create primary 4-mode tensor [System × Breadth × Depth × Phase]
    kernel->cognitive_kernel = ggml_new_tensor_4d(ctx, GGML_TYPE_F32, 
                                                  max_systems, max_breadth, max_depth, 2);
    
    // Create auxiliary structures
    kernel->prime_lookup = ggml_new_tensor_1d(ctx, GGML_TYPE_I32, GGML_COGNITIVE_MAX_PRIMES);
    kernel->matula_embedding = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, 4, 1024); // [coordinates, max_matula]
    kernel->factorization_graph = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, 1024, 1024); // Sparse representation
    
    // Create quantum phase encoding matrices
    kernel->phase_interference = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, max_breadth, max_depth);
    kernel->superposition_states = ggml_new_tensor_3d(ctx, GGML_TYPE_F32, max_systems, max_breadth, max_depth);
    
    // Initialize tensors with default values
    ggml_set_zero(kernel->cognitive_kernel);
    ggml_set_zero(kernel->prime_lookup);
    ggml_set_zero(kernel->matula_embedding);
    ggml_set_zero(kernel->factorization_graph);
    ggml_set_zero(kernel->phase_interference);
    ggml_set_zero(kernel->superposition_states);
    
    // Fill prime lookup tensor
    int32_t* prime_data = (int32_t*)kernel->prime_lookup->data;
    for (size_t i = 0; i < kernel->prime_cache.prime_count && i < GGML_COGNITIVE_MAX_PRIMES; i++) {
        prime_data[i] = (int32_t)kernel->prime_cache.primes[i];
    }
    
    printf("Initialized cognitive kernel tensor: [%u × %u × %u × 2]\n", 
           max_systems, max_breadth, max_depth);
    
    return kernel;
}

// Cleanup cognitive kernel tensor
void ggml_cognitive_kernel_free(ggml_cognitive_kernel_t* kernel) {
    if (kernel) {
        // Note: tensors are owned by the ggml context and will be freed with it
        free(kernel);
    }
}

// Encode tree expression into cognitive kernel tensor
struct ggml_tensor* ggml_cognitive_kernel_encode(
    struct ggml_context* ctx,
    ggml_cognitive_kernel_t* kernel,
    const char* tree_expression) {
    
    ggml_matula_encoding_t encoding = ggml_encode_tree(tree_expression, &kernel->prime_cache);
    
    // Create result tensor
    struct ggml_tensor* result = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, 4);
    float* data = (float*)result->data;
    
    // Store encoding components
    data[0] = (float)encoding.system_level;
    data[1] = (float)encoding.breadth_index;
    data[2] = (float)encoding.depth_index;
    data[3] = (float)encoding.matula_value;
    
    // Update cognitive kernel tensor at the appropriate coordinates
    if (encoding.system_level < kernel->max_systems &&
        encoding.breadth_index < kernel->max_breadth &&
        encoding.depth_index < kernel->max_depth) {
        
        // Access the 4D tensor data
        float* kernel_data = (float*)kernel->cognitive_kernel->data;
        size_t idx = (encoding.system_level * kernel->max_breadth * kernel->max_depth * 2) +
                     (encoding.breadth_index * kernel->max_depth * 2) +
                     (encoding.depth_index * 2);
        
        // Store real and imaginary parts of the phase
        kernel_data[idx] = crealf(encoding.phase);
        kernel_data[idx + 1] = cimagf(encoding.phase);
    }
    
    return result;
}

// Create superposition of tree states
struct ggml_tensor* ggml_cognitive_kernel_superposition(
    struct ggml_context* ctx,
    ggml_cognitive_kernel_t* kernel,
    ggml_tree_tensor_t* tree_states,
    size_t state_count) {
    
    struct ggml_tensor* result = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, state_count, 4);
    float* data = (float*)result->data;
    
    float normalization = 0.0f;
    for (size_t i = 0; i < state_count; i++) {
        normalization += tree_states[i].probability_amplitude * tree_states[i].probability_amplitude;
    }
    normalization = sqrtf(normalization);
    
    for (size_t i = 0; i < state_count; i++) {
        size_t idx = i * 4;
        data[idx] = (float)tree_states[i].matula_value;
        data[idx + 1] = crealf(tree_states[i].phase);
        data[idx + 2] = cimagf(tree_states[i].phase);
        data[idx + 3] = tree_states[i].probability_amplitude / normalization;
    }
    
    return result;
}

// Prime-structured attention implementation
struct ggml_tensor* ggml_prime_attention(
    struct ggml_context* ctx,
    struct ggml_tensor* query,
    struct ggml_tensor* key,
    struct ggml_tensor* value,
    ggml_prime_attention_t* prime_config) {
    
    // For now, implement a simplified version
    // Just return the input query as a placeholder since matrix operations are complex
    (void)key;
    (void)value;
    (void)prime_config;
    
    return query;
}

// Generate phase interference pattern
struct ggml_tensor* ggml_phase_interference_pattern(
    struct ggml_context* ctx,
    ggml_cognitive_kernel_t* kernel,
    uint32_t breadth,
    uint32_t depth) {
    
    struct ggml_tensor* pattern = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, breadth, depth);
    float* data = (float*)pattern->data;
    
    for (uint32_t b = 0; b < breadth; b++) {
        for (uint32_t d = 0; d < depth; d++) {
            // Generate interference pattern based on prime-structured coordinates
            float phase = (float)(b * ggml_nth_prime(d + 1)) * 0.1f;
            data[b * depth + d] = cosf(phase);
        }
    }
    
    return pattern;
}

// Tree tensor composition
ggml_tree_tensor_t ggml_tree_tensor_compose(ggml_tree_tensor_t t1, ggml_tree_tensor_t t2) {
    ggml_tree_tensor_t result = {0};
    
    if (t1.is_prime && t2.is_prime) {
        // Prime × Prime → Composite with phase entanglement
        result.matula_value = t1.matula_value * t2.matula_value;
        result.phase = t1.phase * t2.phase;
        result.is_prime = false;
        result.probability_amplitude = t1.probability_amplitude * t2.probability_amplitude;
    } else if (t1.has_single_skin) {
        // Single skin preservation → Prime encoding
        result.matula_value = ggml_prime_offset(t1.matula_value);
        result.phase = t1.phase;
        result.is_prime = true;
        result.probability_amplitude = t1.probability_amplitude;
    } else {
        // Default composition
        result.matula_value = t1.matula_value + t2.matula_value;
        result.phase = (t1.phase + t2.phase) / 2.0f;
        result.is_prime = false;
        result.probability_amplitude = (t1.probability_amplitude + t2.probability_amplitude) / 2.0f;
    }
    
    return result;
}

// Hypergraph composition of multiple tensors
struct ggml_tensor* ggml_hypergraph_compose(
    struct ggml_context* ctx,
    struct ggml_tensor** tensors,
    size_t tensor_count) {
    
    if (tensor_count == 0) return NULL;
    if (tensor_count == 1) return tensors[0];
    
    // Start with first tensor
    struct ggml_tensor* result = tensors[0];
    
    // Compose with remaining tensors
    for (size_t i = 1; i < tensor_count; i++) {
        result = ggml_add(ctx, result, tensors[i]);
    }
    
    return result;
}

// Cognitive tensor norm
float ggml_cognitive_tensor_norm(struct ggml_tensor* tensor, const char* norm_type) {
    if (!tensor || !tensor->data) return 0.0f;
    
    float* data = (float*)tensor->data;
    size_t n_elements = ggml_nelements(tensor);
    
    if (strcmp(norm_type, "l1") == 0) {
        float sum = 0.0f;
        for (size_t i = 0; i < n_elements; i++) {
            sum += fabsf(data[i]);
        }
        return sum;
    } else if (strcmp(norm_type, "l2") == 0) {
        float sum = 0.0f;
        for (size_t i = 0; i < n_elements; i++) {
            sum += data[i] * data[i];
        }
        return sqrtf(sum);
    } else if (strcmp(norm_type, "inf") == 0) {
        float max_val = 0.0f;
        for (size_t i = 0; i < n_elements; i++) {
            float abs_val = fabsf(data[i]);
            if (abs_val > max_val) max_val = abs_val;
        }
        return max_val;
    }
    
    return 0.0f;
}

// Cognitive tensor similarity
float ggml_cognitive_tensor_similarity(struct ggml_tensor* a, struct ggml_tensor* b) {
    if (!a || !b || !a->data || !b->data) return 0.0f;
    if (ggml_nelements(a) != ggml_nelements(b)) return 0.0f;
    
    float* data_a = (float*)a->data;
    float* data_b = (float*)b->data;
    size_t n_elements = ggml_nelements(a);
    
    float dot_product = 0.0f;
    float norm_a = 0.0f;
    float norm_b = 0.0f;
    
    for (size_t i = 0; i < n_elements; i++) {
        dot_product += data_a[i] * data_b[i];
        norm_a += data_a[i] * data_a[i];
        norm_b += data_b[i] * data_b[i];
    }
    
    if (norm_a == 0.0f || norm_b == 0.0f) return 0.0f;
    
    return dot_product / (sqrtf(norm_a) * sqrtf(norm_b));
}

// Print cognitive tensor statistics
void ggml_cognitive_tensor_print_stats(ggml_cognitive_kernel_t* kernel) {
    if (!kernel) return;
    
    printf("Cognitive Kernel Statistics:\n");
    printf("  Max Systems: %u\n", kernel->max_systems);
    printf("  Max Breadth: %u\n", kernel->max_breadth);
    printf("  Max Depth: %u\n", kernel->max_depth);
    printf("  Prime Cache: %zu primes\n", kernel->prime_cache.prime_count);
    
    if (kernel->cognitive_kernel) {
        printf("  Cognitive Kernel Tensor: ");
        for (int i = 0; i < GGML_MAX_DIMS; i++) {
            if (kernel->cognitive_kernel->ne[i] > 1) {
                printf("%ld ", kernel->cognitive_kernel->ne[i]);
            }
        }
        printf("\n");
    }
}